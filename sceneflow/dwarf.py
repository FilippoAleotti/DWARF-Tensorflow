'''
Dwarf network

Author: Filippo Aleotti
Mail: filippo.aleotti2@unibo.it
'''

import tensorflow as tf
from modules.dwarf import DwarfDecoder as Decoder
from modules.pwc import Encoder
from main_utils.ops import regularization_term, l1_loss
from main_utils.flow_utils import flow_to_color
from main_utils.image_utils import error_image
from main_utils.ops import downsample_image
from main_utils.disp_utils import color_disparity
from general.network import GeneralNetwork

class Dwarf(GeneralNetwork):

    def build_model(self):
        ''' Network specification'''
        self.prepare_network_parameters()
        
        # Encoder with shared weights
        encoder_left_t0 = Encoder(self.left_t0)
        encoder_right_t0 = Encoder(self.right_t0)
        encoder_left_t1 = Encoder(self.left_t1)
        encoder_right_t1 = Encoder(self.right_t1)

        features = self.memorize_encoders_features(
            encoder_left_t0, encoder_right_t0, encoder_left_t1, encoder_right_t1)

        # Decoder
        decoder = Decoder(
            encoder_features=features, 
            height=self.height,
            width=self.width,
            max_displacement=self.max_displacement, 
            max_depth_displacement=self.max_depth_displacement,
            scale_factor=self.scale_factor, 
            is_training=self.training,
            use_dense_connection=self.use_dense_connection,
            final_layer_index=self.final_layer_index, 
            use_volumes_correlation=self.use_volumes_correlation,
            use_context=self.use_context
        )
        self.predicted_motion_vectors = decoder.motion_vectors

    def prepare_network_parameters(self):
        self.left_t0 = self.inputs['left_t0']
        self.left_t1 = self.inputs['left_t1']
        self.right_t0 = self.inputs['right_t0']
        self.right_t1 = self.inputs['right_t1']
        _, self.height, self.width, _ = self.left_t0.get_shape().as_list()
        self.use_dense_connection = self.params['network']['use_dense_connections']
        self.use_context = self.params['network']['use_context']
        self.max_displacement = self.params['network']['max_displacement']
        self.max_depth_displacement = self.params['network']['max_depth_displacement']
        self.scale_factor=self.params['network']['scale_factor']
        self.number_of_scales= self.params['network']['number_of_scales']
        self.number_of_sceneflows= self.params['network']['number_of_sceneflows']
        self.starting_index = self.number_of_scales- self.number_of_sceneflows
        self.final_layer_index = self.number_of_scales - self.number_of_sceneflows
        self.use_volumes_correlation = self.params['network']['use_volumes_correlation']
        self.final_resizing_method = self.params['network']['final_resizing_method']
        assert self.final_resizing_method in ['RESIZE', 'CROP']

        if self.training:
            self.pyramidal_gt=self.params['network']['use_pyramidal_gt']
            self.optical_flow_weight = self.params['network']['optical_flow_weight']
            self.max_output=self.params['network']['max_output']
            self.gamma=self.params['network']['gamma']
            self.alphas = self.params['network']['alphas']
            self.color_disparity_factor = self.params['network']['color_disparity_factor']

    def memorize_encoders_features(self, enc_left_t0, enc_right_t0, enc_left_t1, enc_right_t1):
        with tf.variable_scope('memorize_encoders_features'):
            features={
                    'left_t0': enc_left_t0.features,
                    'right_t0': enc_right_t0.features,
                    'left_t1': enc_left_t1.features,
                    'right_t1': enc_right_t1.features
                }
        return features
    
    def build_outputs(self):
        ''' Output generated by the network'''
        if self.training:
            with tf.variable_scope('ground_truth'):
                self.gt_motion_vectors = self.create_gt_motion_vectors(self.pyramidal_gt)
        else:
            with tf.variable_scope('build_outputs'):
                final_shape = self.inputs['final_shape']
                self.outputs = self.extract_final_motion_vectors(self.predicted_motion_vectors, final_shape)

    def build_losses(self):
        ''' Losses used by the network. Remeber to increment total_loss'''
        with tf.variable_scope('losses'):
            self.total_loss = 0.
            self.decoders_loss = []
            
            for i in range(self.starting_index):
                self.decoders_loss.append(0)
            
            for i in range(self.starting_index, self.number_of_scales):
                print('level:{} , loss_weight:{}'.format(i,self.alphas[i]))
                loss_optical_flow = l1_loss(self.predicted_motion_vectors[i]['forward_flow'], self.gt_motion_vectors[i]['forward_flow'], self.alphas[i])
                loss_disparity  = l1_loss(self.predicted_motion_vectors[i]['disparity'], self.gt_motion_vectors[i]['disparity'], self.alphas[i])
                loss_disparity_change = l1_loss(self.predicted_motion_vectors[i]['disparity_change'], self.gt_motion_vectors[i]['disparity_change'], self.alphas[i])
                loss = self.optical_flow_weight * loss_optical_flow + loss_disparity + loss_disparity_change
                self.total_loss += loss
                self.decoders_loss.append(loss)
                if i == self.starting_index:
                    self.loss_disparity = loss_disparity
                    self.loss_disparity_change = loss_disparity_change
                    self.loss_optical_flow = loss_optical_flow
            self.regularization_loss = regularization_term(self.gamma)

            self.total_loss += self.regularization_loss

    def build_summaries(self):
        ''' Summaries'''
        super().build_summaries()
        with tf.variable_scope('summaries'):
            with tf.variable_scope('ground_truth'):
                self.colored_gt_motion_vectors = self.color_motion_vectors(self.gt_motion_vectors, self.scale_factor)
            with tf.variable_scope('predicted_sceneflow'):
                self.color_predicted_motion_vectors = self.color_motion_vectors(self.predicted_motion_vectors, self.scale_factor)
                self.error_images = self.create_error_images(self.predicted_motion_vectors, self.gt_motion_vectors)
            
            for i in range(self.starting_index, self.number_of_scales):
                with tf.variable_scope('level_'+str(i)):
                    tf.summary.scalar('loss_decoder', self.decoders_loss[i])
                    self.insert_summary_image('forward_flow',i)
                    self.insert_summary_image('disparity',i)
                    self.insert_summary_image('disparity_change',i)
                    tf.summary.image('error_flow', self.error_images[i]['forward_flow'], max_outputs=self.max_output)
                    tf.summary.image('error_disparity', self.error_images[i]['disparity'], max_outputs=self.max_output)
                    tf.summary.image('error_disparity_change', self.error_images[i]['disparity_change'], max_outputs=self.max_output)
                    tf.summary.scalar('weight', self.alphas[i])

                    if i==self.starting_index:
                        tf.summary.scalar('loss_optical_flow', self.loss_optical_flow)
                        tf.summary.scalar('loss_disparity', self.loss_disparity)
                        tf.summary.scalar('loss_disparity_change', self.loss_disparity_change)

            with tf.variable_scope('images'):
                tf.summary.image('left_t0',   self.left_t0,  max_outputs=self.max_output)
                tf.summary.image('left_t1',   self.left_t1,  max_outputs=self.max_output)
                tf.summary.image('right_t0',  self.right_t0, max_outputs=self.max_output)
                tf.summary.image('right_t1',  self.right_t1, max_outputs=self.max_output)

            tf.summary.scalar('gamma' , self.gamma)
            tf.summary.scalar('max_displacement' , self.max_displacement)
            tf.summary.scalar('optical_flow_weight' , self.optical_flow_weight)
            tf.summary.scalar('scale_factor' , self.scale_factor)
            tf.summary.scalar('regularization' , self.regularization_loss)

    def create_error_images(self, predicted, gt, mask_list=None):
        '''
        Create a list of error images for optical flows
        '''
        with tf.variable_scope('create_error_images'):
            error_images = []
            
            for i in range(self.starting_index):
                error_images.append(None)
            if mask_list is None:
                with tf.variable_scope('creating_masks'):
                    mask_list = []
                    for i in range(0, self.starting_index):                    
                        mask_list.append(None)

                    for i in range(self.starting_index, self.number_of_scales):
                        batch, height, width, _ =  predicted[i]['forward_flow'].shape # note that all motions have same shape
                        ones = tf.ones([batch, height, width, 1], tf.float32)
                        mock_mask = {
                            'forward_flow': ones,
                            'disparity': ones,
                            'disparity_change': ones,
                        }
                        mask_list.append(mock_mask)
                    
            for i in range(self.starting_index, self.number_of_scales):
                mask = mask_list[i]

                error_image_flow = error_image(predicted[i]['forward_flow'],
                    gt[i]['forward_flow'], mask['forward_flow'])
                error_image_disparity = error_image(predicted[i]['disparity'],
                    gt[i]['disparity'], mask['disparity'])
                error_image_disparity_change = error_image(predicted[i]['disparity_change'],
                    gt[i]['disparity_change'], mask['disparity_change'])

                error_motions = {
                    'forward_flow': error_image_flow,
                    'disparity': error_image_disparity,
                    'disparity_change':error_image_disparity_change
                }
                error_images.append(error_motions)
        return error_images

    def create_gt_motion_vectors(self, pyramidal=True):
        with tf.variable_scope('create_gt_motion_vectors'):
            gt_motion_vectors = {}
            gt_motion_vectors['forward_flow'] = self.inputs['gt_flow'] 
            gt_motion_vectors['disparity'] = self.inputs['gt_disparity'] 
            gt_motion_vectors['disparity_change'] = self.inputs['gt_disparity_change']
            starting_index = self.number_of_scales - self.number_of_sceneflows 
            if pyramidal:
                gt_motion_vectors = self.create_motion_pyramid(gt_motion_vectors, scaling_factor=1./self.scale_factor,
                    starting_index=0, number_of_layers=self.number_of_scales)
            else:
                # scale each motion component by scaling_factor
                for motion in gt_motion_vectors.keys():
                    gt_motion_vectors[motion] *= 1./self.scale_factor 
                return [gt_motion_vectors]*self.number_of_scales
        return gt_motion_vectors

    def insert_summary_image(self, name, index, max_out=1):
        with tf.variable_scope(name):
            if self.color_predicted_motion_vectors[index][name] is not None:
                tf.summary.image('predicted', 
                    self.color_predicted_motion_vectors[index][name], max_outputs=max_out)
            if self.colored_gt_motion_vectors[index][name] is not None:
                tf.summary.image('ground_truth', 
                    self.colored_gt_motion_vectors[index][name], max_outputs=max_out)

    def color_motion_vectors(self, motion_vectors, scale_factor):
        '''
            Apply colormaps to each element in each motion vectors
        '''
        with tf.variable_scope('color_motion_vectors'):
            colored_motion_vectors = []

            for i in range(self.starting_index):
                colored_motion_vectors.append(None)

            for i in range(self.starting_index,self.number_of_scales):
                colored_motion = {}
                colored_motion['forward_flow'] = flow_to_color(motion_vectors[i]['forward_flow'] * scale_factor) 
                colored_motion['disparity']  = color_disparity(motion_vectors[i]['disparity']* scale_factor, self.color_disparity_factor)
                colored_motion['disparity_change'] = color_disparity(motion_vectors[i]['disparity_change'] * scale_factor, self.color_disparity_factor) 
                colored_motion_vectors.append(colored_motion)
        return colored_motion_vectors

    def create_motion_pyramid(self, motion_vectors, scaling_factor, number_of_layers, starting_index):
        '''
            Given the motion vector dict at full scale, this method
            creates a pyramid, starting to collect data from starting_index
            (i.e., first starting_index maps are discarded and the full pyramid 
            is made up by (number_of_layer - starting_index) layers.

            Returns:
                A list of dicts. For each scale (i.e, index), there are all motion vectors rescaled
                at that resolution 
        '''
        with tf.variable_scope('create_motion_pyramid'):
            pyramid_motion_vectors =[]

            for i in range(starting_index, number_of_layers):
                downsampled_motion_vector = {}
                for motion_name, motion_value in motion_vectors.items():
                    downsampled_motion_value = None
                    if motion_value is not None:
                        downsampled_motion_value = downsample_image(motion_vectors[motion_name], self.height, self.width, i) * scaling_factor
                    downsampled_motion_vector[motion_name]= downsampled_motion_value

                pyramid_motion_vectors.append(downsampled_motion_vector)

        return pyramid_motion_vectors
    
    def extract_final_motion_vectors(self, motion_vector, final_shape):
        '''
            Extract each component of a motion vector and apply a bilinear upsampling
            operation to get fullsize resolution.
            Since values are estimated at 1/factor at each scale, each value is
            rescaled by factor
        '''
        with tf.variable_scope('extract_final_motion_vectors'):
            final_motion_vector = {}
            names = ['forward_flow', 'disparity_change', 'disparity']
            for motion in motion_vector:
                for name in names:
                    vector = motion_vector[0][name] * self.scale_factor
                    vector = tf.image.resize_bilinear(vector, [self.height, self.width])
                    final_height= tf.cast(final_shape[0], tf.float32)
                    final_width= tf.cast(final_shape[1], tf.float32)
                    
                    if self.final_resizing_method == 'RESIZE':
                        vector = tf.squeeze(vector, axis=0)

                        scaling_factor_width = final_width / self.width
                        scaling_factor_height = final_height/ self.height
                        
                        if name == 'forward_flow':
                            scalings = tf.ones(2, tf.float32) * [scaling_factor_width, scaling_factor_height]
                            vector = vector * scalings
                            
                        else:
                            vector = vector * scaling_factor_width
                        
                        vector = tf.image.resize_bilinear(tf.expand_dims(vector, 0), [final_shape[0], final_shape[1]])        
        
                    else:
                        final_height = tf.cast(final_height, tf.int32)
                        final_width = tf.cast(final_width, tf.int32)
                        h_pad = (self.height - final_height) // 2
                        w_pad = (self.width  - final_width)  // 2
                        vector = tf.slice(vector, [0, h_pad, w_pad, 0],[-1, final_height, final_width,-1])
                    
                    vector = tf.squeeze(vector, axis=0)
                    final_motion_vector[name] = vector
        return final_motion_vector